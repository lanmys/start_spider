import json
import os
import re
import time
import pymongo
from bs4 import BeautifulSoup
import requests
from urllib.parse import urlencode
from hashlib import md5

#config
MONGO_URL='localhost'
MONGO_DB='toutiao'
MONGO_TABLE='toutiao'

client = pymongo.MongoClient(MONGO_URL)
db = client[MONGO_DB]

def get_page_index(offset,keyword):
    data = {
        'aid': 24,
        'app_name': 'web_search',
        'offset': offset,
        'format': 'json',
        'keyword': keyword,
        'autoload': 'true',
        'count': 20,
        'en_qc': 1,
        'cur_tab': 1,
    }
    #url = 'https://www.toutiao.com/api/search/content/?aid=24&app_name=web_search&offset=60&format=json&keyword=%E8
    # %A1%97%E6%8B%8D&autoload=true&count=20&en_qc=1&cur_tab=1&from=search_tab&pd=synthesis&timestamp=1582515614320'
    url = 'https://www.toutiao.com/api/search/content/?' + urlencode(data)
    cookies = {
        'cookie': 'tt_webid = 6796482268849833480;ttcid=4d815631308145ff867f1fe8f189597242;WEATHER_CITY = %E5%8C%97%E4%BA%AC;tt_webid = 6796482268849833480;csrftoken = c473e3f4fc871f59af630fac5277ce5c;s_v_web_id = verify_k6zw0wpz_Dh4GK27U_AuGs_4gpo_91p2_uodpadopKqgw;__tasessionId = v0comewpg1582514083714;tt_scid = HFL8RgSaJWADCPmTcZkfIXEQDsf2Q9GiTkulYpbBfL6fbI44vPr4Lo - zUwljIV1G7596'
    }
    headers= {
        'user - agent': 'Mozilla / 5.0(Windows NT 10.0;WOW64) AppleWebKit / 537.36(KHTML, likeGecko) Chrome / 80.0.3987.116Safari / 537.36'
    }
    response = requests.get(url,cookies=cookies,headers=headers)
    try:
        response.raise_for_status()
        response.status_code = response.apparent_encoding
        return response.text
    except:
        print('请求索引页出错')
        return None

def parse_page_index(html):
    data = json.loads(html)    #使用json格式化获得的html代码
    if data and 'data' in data.keys():       #判断data中是否有data键
        for item in data.get('data'):
            yield item.get('article_url')

def get_page_detail(url):
    cookies = {
        'cookie': 'tt_webid = 6796482268849833480;ttcid=4d815631308145ff867f1fe8f189597242;WEATHER_CITY = %E5%8C%97%E4%BA%AC;tt_webid = 6796482268849833480;csrftoken = c473e3f4fc871f59af630fac5277ce5c;s_v_web_id = verify_k6zw0wpz_Dh4GK27U_AuGs_4gpo_91p2_uodpadopKqgw;__tasessionId = v0comewpg1582514083714;tt_scid = HFL8RgSaJWADCPmTcZkfIXEQDsf2Q9GiTkulYpbBfL6fbI44vPr4Lo - zUwljIV1G7596'
    }
    headers = {
        'user - agent': 'Mozilla / 5.0(Windows NT 10.0;WOW64) AppleWebKit / 537.36(KHTML, likeGecko) Chrome / 80.0.3987.116Safari / 537.36'
    }
    response = requests.get(url, cookies=cookies, headers=headers)
    try:
        response.raise_for_status()
        response.status_code = response.apparent_encoding
        return response.text
    except:
        print('未能获取目标网页')

def parse_page_detail(html):
    soup = BeautifulSoup(html,'lxml')
    title = soup.select('title')[0].get_text()
    print(title)
    image_pattern = re.compile(r'gallery: JSON.parse\((.*?)\),', re.S)
    result = re.search(image_pattern, html)

    if result:
        result = re.sub(r'\\', '', result.group(1))
        result = re.sub(r'u002F', '/', result)
        result = result[1:-1]
        print(result)
        data = json.loads(result)
        if data and 'sun_images' in data.keys():
            sub_images = data.get('sub_images')
            images = [item.get('url') for item in sub_images]
            for image in images:
                download_image(image)
            msg = {
                'title' : title,
                'images' : images,
            }
            return msg

    else:
        print('未能获取到街拍图片的url')

def save_to_mongo(result):
    if db[MONGO_TABLE].insert(result):
        print('存储到MongoDB成功',result)
        return True
    return False

def download_image(url):
    print('正在下载',url)
    try:
        response = requests.get(url)
        if response.status_code == 200:
            return response.text
        return None
    except:
        print('请求图片出错',url)
        return None

def save_image(content):
    file_path = '{0}/{1}.{2}'.format(os.getcwd(),md5(content).hexdigest(),'jpg')
    if not os.path.exists(file_path):
        with open(file_path,'wb') as f:
            f.write(content)
            f.close()
def main():
    html = get_page_index(0,'街拍')    #获取街拍的网页源代码
    for url in parse_page_index(html):      #获取街拍图片每个文章的url

        if url:
            html = get_page_detail(url)     #获取文章的html
            if html:
                result = parse_page_detail(html)   #获取图片的url
                print(type(result))
                #save_to_mongo(result)
                time.sleep(5)
            else:
                print('未能获取图片的url')
                continue
        else:
            print('未能获取文章的html')
            continue


if  __name__ == '__main__':
    main()
