## Scrapy框架的介绍

 - 安装：
   - $ pip install scrapy
   - 如果遇见版本错误则：
     - $ pip install --upgrade incremental
     - $ pip install Twisted      #因为scrapy框架就是依赖于这个twisted框架
     - $ pip install scrapy

  - 关于scrapy框架的常用命令：
    - startproject:创建一个新工程:scrapy startproject <name> [dir]
    - genspider:创建一个爬虫:scrapy genspider [options] <name> <domain>
    - settings:获取爬虫配置信息:scrapy settings [options]
    - crawl:运行一个爬虫: scrapy crawl<spider>
    - list:列出工程中所有爬虫：scrapy list
    - shell:启动URL调试命令行：scrapy shell [url]
    - 例子：
      - 1.在桌面创建一个名叫demo的项目：cmd环境下：$ scrapy startproject demo
      - 2.使用scrapy命令生成爬虫：进入文件夹~\demo\demo\spiders\  :$ scrapy genspider demo "www.baidu.com"
      - 3.

  - 关于项目工程中文件的概述：
    - scrapy.cfg ：项目的配置文件
    - mySpider/ ：项目的Python模块，将会从这里引用代码
    - mySpider/items.py ：项目的目标文件
    - mySpider/pipelines.py ：项目的管道文件
    - mySpider/settings.py ：项目的设置文件
    - mySpider/spiders/ ：存储爬虫代码目录


  - 制作scrapy爬虫四步：
    - 新建项目：scrapy startproject xxx ：新建一个新的爬虫项目
    - 明确目标： 编写items.py：明确你想要抓取的内容
    - 制作爬虫： spiders/xxspider.py：制作爬虫开始爬取网页
    - 存储内容: pipelins.py:设置管道存储爬取内容
